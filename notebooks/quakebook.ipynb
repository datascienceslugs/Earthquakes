{"cells":[{"source":["import pandas as pd\n","import numpy as np\n","import gc as gc\n","from glob import glob\n","from tqdm import tqdm\n","from sklearn.impute import SimpleImputer\n",""],"cell_type":"code","outputs":[],"metadata":{},"execution_count":0},{"source":["def get_predictors(filepath, col_name, seg_len, data_len):\n","    num_features = 12\n","    num_segs = data_len // seg_len + 1\n","    predictors = np.empty((num_segs, num_features))\n","    i = 0\n","    \n","    for seg in tqdm(pd.read_csv(filepath, usecols = [col_name],\n","                                chunksize = seg_len, dtype = np.int16)):\n","        # calculate features from seg\n","        predictors[i, 0] = seg.max()\n","        predictors[i, 1] = seg.sum()\n","        predictors[i, 2] = seg.mean()\n","        predictors[i, 3] = seg.var()\n","        predictors[i, 4] = seg.kurtosis()\n","        predictors[i, 5] = seg.skew()\n","        predictors[i, 6] = seg.quantile(q = 0.25)\n","        predictors[i, 7] = seg.quantile(q = 0.5)\n","        predictors[i, 8] = seg.quantile(q = 0.75)\n","        predictors[i, 9] = seg.quantile(q = 0.95)\n","        predictors[i, 10] = seg.mad()\n","        predictors[i, 11] = seg.sem()\n","        i += 1\n","    \n","    imputer = SimpleImputer(strategy = 'median') \n","    return imputer.fit_transform(predictors)\n",""],"cell_type":"code","outputs":[],"metadata":{},"execution_count":0},{"source":["def get_responses(filepath, col_name, seg_len, data_len):\n","    num_segs = data_len // seg_len + 1\n","    responses = np.empty(num_segs)\n","    i = 0\n","    for seg in tqdm(pd.read_csv(filepath, usecols = [col_name], \n","                                chunksize = seg_len, dtype = np.float16)):\n","        responses[i] = seg.values[-1]\n","        i += 1\n","\n","    return responses\n",""],"cell_type":"code","outputs":[],"metadata":{},"execution_count":0},{"source":["def get_test_predictors(file_directory, seg_len, num_segs):\n","    num_features = 12\n","    test_predictors = np.empty((num_segs, num_features)) \n","    i = 0\n","\n","    for fname in tqdm(glob(file_directory)):\n","        seg  = pd.read_csv(fname, dtype = np.int16)\n","        # calculate features from seg\n","        test_predictors[i, 0] = seg.max()\n","        test_predictors[i, 1] = seg.sum()\n","        test_predictors[i, 2] = seg.mean()\n","        test_predictors[i, 3] = seg.var()\n","        test_predictors[i, 4] = seg.kurtosis()\n","        test_predictors[i, 5] = seg.skew()\n","        test_predictors[i, 6] = seg.quantile(q = 0.25)\n","        test_predictors[i, 7] = seg.quantile(q = 0.5)\n","        test_predictors[i, 8] = seg.quantile(q = 0.75)\n","        test_predictors[i, 9] = seg.quantile(q = 0.95)\n","        test_predictors[i, 10] = seg.mad()\n","        test_predictors[i, 11] = seg.sem()\n","        i += 1\n","\n","    imputer = SimpleImputer(strategy = 'median')\n","    return imputer.fit_transform(test_predictors)\n",""],"cell_type":"code","outputs":[],"metadata":{},"execution_count":0},{"source":["SEG_LEN = 150000      # Length of a segment of test data\n","DATA_LEN = 629145480  # Length of the entire time series\n","NUM_SEGS = 2624       # number of data segments in input/train\n",""],"cell_type":"code","outputs":[],"metadata":{},"execution_count":0},{"source":["X_train = get_predictors('input/train.csv', 'acoustic_data', SEG_LEN, DATA_LEN)"],"cell_type":"code","outputs":[],"metadata":{},"execution_count":0},{"source":["y_train = get_responses('input/train.csv', 'time_to_failure', SEG_LEN, DATA_LEN)"],"cell_type":"code","outputs":[],"metadata":{},"execution_count":0},{"source":["X_test = get_test_predictors('input/test/*.csv', SEG_LEN, NUM_SEGS)\n",""],"cell_type":"code","outputs":[],"metadata":{},"execution_count":0},{"source":["y_train.shape"],"cell_type":"code","outputs":[],"metadata":{},"execution_count":0},{"source":["X_test.shape\n","# saves predictors and responses for easier access in the future"],"cell_type":"code","outputs":[],"metadata":{},"execution_count":0},{"source":["np.savetxt(\"y_train.csv\", y_train, delimiter = \",\")"],"cell_type":"code","outputs":[],"metadata":{},"execution_count":0},{"source":["np.savetxt(\"X_train.csv\", X_train, delimiter = \",\")"],"cell_type":"code","outputs":[],"metadata":{},"execution_count":0},{"source":["np.savetxt(\"X_test.csv\", X_test, delimiter = ',')\n",""],"cell_type":"code","outputs":[],"metadata":{},"execution_count":0},{"source":["X_train = pd.read_csv(\"X_train.csv\", header = None)\n","y_train = pd.read_csv(\"y_train.csv\", header = None)\n","X_test = pd.read_csv('X_test.csv', header = None)\n",""],"cell_type":"code","outputs":[],"metadata":{},"execution_count":0},{"source":["from sklearn.ensemble import RandomForestRegressor\n","from sklearn.model_selection import GridSearchCV\n","from sklearn.metrics import mean_absolute_error, make_scorer\n",""],"cell_type":"code","outputs":[],"metadata":{},"execution_count":0},{"source":["rf = RandomForestRegressor(max_depth = 7)\n",""],"cell_type":"code","outputs":[],"metadata":{},"execution_count":0},{"source":["rf.fit(X_train, y_train)\n",""],"cell_type":"code","outputs":[],"metadata":{},"execution_count":0},{"source":["y_pred = rf.predict(X_test)\n",""],"cell_type":"code","outputs":[],"metadata":{},"execution_count":0},{"source":["param_grid = {\n","                'n_estimators': [10,20,50,100,200,500],\n","                'max_depth'   : [5,10,20, 50, 100, None],\n","                'max_features': ['auto', 'sqrt', 'log2']\n","              }\n","\n","rf = RandomForestRegressor\n","reg = GridSearchCV(rf,  \n","                   param_grid = param_grid,\n","                   cv = 5,\n","                   scoring = make_scorer(mean_absolute_error,\n","                                                 greater_is_better= False)\n","                  )\n",""],"cell_type":"code","outputs":[],"metadata":{},"execution_count":0},{"source":["reg.fit(X_train, y_train)\n",""],"cell_type":"code","outputs":[],"metadata":{},"execution_count":0},{"source":["reg.best_params_\n","reg.best_score_\n",""],"cell_type":"code","outputs":[],"metadata":{},"execution_count":0},{"source":["y_pred = reg.predict(X_test)\n","\n","\n","# Build submission CSV file using results"],"cell_type":"code","outputs":[],"metadata":{},"execution_count":0},{"source":["seg_names = []\n","for fname in glob('input/test/*.csv'):\n","    seg_names.append(fname[11:21]) # modify to 13:24 if on kaggle kernel\n",""],"cell_type":"code","outputs":[],"metadata":{},"execution_count":0},{"source":["submission = pd.DataFrame({'seg_id': seg_names, 'time_to_failure': y_pred})\n","submission.to_csv('submission.csv', index = False)"],"cell_type":"code","outputs":[],"metadata":{},"execution_count":0}],"nbformat":4,"nbformat_minor":2,"metadata":{"language_info":{"name":"python","codemirror_mode":{"name":"ipython","version":3}},"orig_nbformat":2,"file_extension":".py","mimetype":"text/x-python","name":"python","npconvert_exporter":"python","pygments_lexer":"ipython3","version":3}}